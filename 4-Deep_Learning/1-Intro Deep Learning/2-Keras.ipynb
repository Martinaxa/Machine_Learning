{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl (272.8 MB)\n",
      "     -------------------------------------- 272.8/272.8 MB 6.1 MB/s eta 0:00:00\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 18.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.22.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.2-cp310-abi3-win_amd64.whl (422 kB)\n",
      "     ------------------------------------- 422.5/422.5 kB 27.5 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.11.tar.gz (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 16.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     --------------------------------------- 24.4/24.4 MB 21.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (63.4.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.2-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 21.9 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "     ------------------------------------- 440.7/440.7 kB 26.9 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 24.0 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 18.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 21.0 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.5/126.5 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.7.3)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Downloading ml_dtypes-0.1.0-cp310-cp310-win_amd64.whl (120 kB)\n",
      "     -------------------------------------- 120.4/120.4 kB 6.9 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.19.1-py2.py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.3/181.3 kB 10.7 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
      "     ------------------------------------- 242.5/242.5 kB 14.5 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.9/93.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.3/181.3 kB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.9/83.9 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.11-py3-none-any.whl size=1487992 sha256=991ace202abd8120a6a9cde836c735bd0f1ad21756c7a94ec17f5b37e243359e\n",
      "  Stored in directory: c:\\users\\mareg\\appdata\\local\\pip\\cache\\wheels\\24\\d2\\da\\9e8cec7afad3784f022c4dd1184ba33f9220a9d24b712e50eb\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, ml-dtypes, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.19.1 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.2 h5py-3.8.0 jax-0.4.11 keras-2.12.0 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.1.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.2 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 werkzeug-2.3.4\n",
      "Requirement already satisfied: keras in c:\\users\\mareg\\anaconda3\\envs\\general\\lib\\site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    " !pip install tensorflow\n",
    " !pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential() #todas las redes neuronales son secuenciales \n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.reshaping.flatten.Flatten object at 0x000001C4FAB06E30>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3138 - accuracy: 0.6582 - val_loss: 0.6208 - val_accuracy: 0.8641\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5274 - accuracy: 0.8650 - val_loss: 0.3989 - val_accuracy: 0.8960\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.4020 - accuracy: 0.8904 - val_loss: 0.3372 - val_accuracy: 0.9079\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.9013 - val_loss: 0.3055 - val_accuracy: 0.9159\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.3213 - accuracy: 0.9095 - val_loss: 0.2843 - val_accuracy: 0.9202\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.2996 - accuracy: 0.9147 - val_loss: 0.2683 - val_accuracy: 0.9243\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.2823 - accuracy: 0.9197 - val_loss: 0.2552 - val_accuracy: 0.9273\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.2677 - accuracy: 0.9239 - val_loss: 0.2441 - val_accuracy: 0.9304\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.2549 - accuracy: 0.9277 - val_loss: 0.2338 - val_accuracy: 0.9336\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.2439 - accuracy: 0.9306 - val_loss: 0.2259 - val_accuracy: 0.9358\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.2338 - accuracy: 0.9336 - val_loss: 0.2172 - val_accuracy: 0.9385\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.2246 - accuracy: 0.9368 - val_loss: 0.2101 - val_accuracy: 0.9428\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.2160 - accuracy: 0.9385 - val_loss: 0.2033 - val_accuracy: 0.9438\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.2081 - accuracy: 0.9412 - val_loss: 0.1985 - val_accuracy: 0.9457\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9432 - val_loss: 0.1913 - val_accuracy: 0.9477\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1941 - accuracy: 0.9447 - val_loss: 0.1856 - val_accuracy: 0.9506\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1875 - accuracy: 0.9466 - val_loss: 0.1809 - val_accuracy: 0.9512\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1814 - accuracy: 0.9485 - val_loss: 0.1755 - val_accuracy: 0.9541\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.1758 - accuracy: 0.9499 - val_loss: 0.1731 - val_accuracy: 0.9534\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1703 - accuracy: 0.9515 - val_loss: 0.1685 - val_accuracy: 0.9547\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1654 - accuracy: 0.9526 - val_loss: 0.1624 - val_accuracy: 0.9570\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.1606 - accuracy: 0.9535 - val_loss: 0.1595 - val_accuracy: 0.9575\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1558 - accuracy: 0.9556 - val_loss: 0.1560 - val_accuracy: 0.9585\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1515 - accuracy: 0.9565 - val_loss: 0.1521 - val_accuracy: 0.9595\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1475 - accuracy: 0.9578 - val_loss: 0.1495 - val_accuracy: 0.9595\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 0.9589 - val_loss: 0.1468 - val_accuracy: 0.9598\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.1395 - accuracy: 0.9601 - val_loss: 0.1445 - val_accuracy: 0.9615\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1360 - accuracy: 0.9611 - val_loss: 0.1417 - val_accuracy: 0.9619\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1326 - accuracy: 0.9622 - val_loss: 0.1387 - val_accuracy: 0.9622\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.1290 - accuracy: 0.9632 - val_loss: 0.1365 - val_accuracy: 0.9627\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1260 - accuracy: 0.9641 - val_loss: 0.1341 - val_accuracy: 0.9642\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1228 - accuracy: 0.9650 - val_loss: 0.1326 - val_accuracy: 0.9641\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.1199 - accuracy: 0.9658 - val_loss: 0.1307 - val_accuracy: 0.9641\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1170 - accuracy: 0.9667 - val_loss: 0.1287 - val_accuracy: 0.9654\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1144 - accuracy: 0.9676 - val_loss: 0.1260 - val_accuracy: 0.9659\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1116 - accuracy: 0.9682 - val_loss: 0.1252 - val_accuracy: 0.9660\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1090 - accuracy: 0.9694 - val_loss: 0.1233 - val_accuracy: 0.9665\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9697 - val_loss: 0.1209 - val_accuracy: 0.9674\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9705 - val_loss: 0.1187 - val_accuracy: 0.9676\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9714 - val_loss: 0.1193 - val_accuracy: 0.9678\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0998 - accuracy: 0.9717 - val_loss: 0.1164 - val_accuracy: 0.9690\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9726 - val_loss: 0.1150 - val_accuracy: 0.9689\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0957 - accuracy: 0.9731 - val_loss: 0.1137 - val_accuracy: 0.9688\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0935 - accuracy: 0.9739 - val_loss: 0.1130 - val_accuracy: 0.9695\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0916 - accuracy: 0.9747 - val_loss: 0.1112 - val_accuracy: 0.9696\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.0898 - accuracy: 0.9752 - val_loss: 0.1096 - val_accuracy: 0.9697\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.0880 - accuracy: 0.9756 - val_loss: 0.1088 - val_accuracy: 0.9699\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.0860 - accuracy: 0.9759 - val_loss: 0.1076 - val_accuracy: 0.9699\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.0844 - accuracy: 0.9769 - val_loss: 0.1087 - val_accuracy: 0.9709\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0827 - accuracy: 0.9770 - val_loss: 0.1057 - val_accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0821 - accuracy: 0.9769 - val_loss: 0.1057 - val_accuracy: 0.9708\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0790 - accuracy: 0.9778 - val_loss: 0.1025 - val_accuracy: 0.9708\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0760 - accuracy: 0.9792 - val_loss: 0.1007 - val_accuracy: 0.9712\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0731 - accuracy: 0.9799 - val_loss: 0.1009 - val_accuracy: 0.9718\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0706 - accuracy: 0.9813 - val_loss: 0.0999 - val_accuracy: 0.9732\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0680 - accuracy: 0.9815 - val_loss: 0.0958 - val_accuracy: 0.9737\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0656 - accuracy: 0.9824 - val_loss: 0.0946 - val_accuracy: 0.9736\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0634 - accuracy: 0.9828 - val_loss: 0.0940 - val_accuracy: 0.9736\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0610 - accuracy: 0.9842 - val_loss: 0.0925 - val_accuracy: 0.9741\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0589 - accuracy: 0.9844 - val_loss: 0.0927 - val_accuracy: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c481517580>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 50, 'steps': 391}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [1.313822865486145,\n",
       "  0.5273887515068054,\n",
       "  0.40201082825660706,\n",
       "  0.35152527689933777,\n",
       "  0.3213057219982147,\n",
       "  0.29957443475723267,\n",
       "  0.2823467254638672,\n",
       "  0.2676509916782379,\n",
       "  0.25494110584259033,\n",
       "  0.2439156323671341,\n",
       "  0.2337842434644699,\n",
       "  0.22457699477672577,\n",
       "  0.21599292755126953,\n",
       "  0.2081490308046341,\n",
       "  0.2009105086326599,\n",
       "  0.19405585527420044,\n",
       "  0.18748623132705688,\n",
       "  0.18136237561702728,\n",
       "  0.17583927512168884,\n",
       "  0.17025665938854218,\n",
       "  0.16537919640541077,\n",
       "  0.1605926901102066,\n",
       "  0.15580932796001434,\n",
       "  0.15151149034500122,\n",
       "  0.1474505513906479,\n",
       "  0.14343059062957764,\n",
       "  0.13950799405574799,\n",
       "  0.13596297800540924,\n",
       "  0.132553368806839,\n",
       "  0.12904271483421326,\n",
       "  0.12600766122341156,\n",
       "  0.12282603234052658,\n",
       "  0.11985959857702255,\n",
       "  0.11701331287622452,\n",
       "  0.11435963958501816,\n",
       "  0.11158638447523117,\n",
       "  0.10898932814598083,\n",
       "  0.10667763650417328,\n",
       "  0.10423775762319565,\n",
       "  0.10197427868843079,\n",
       "  0.09975337237119675,\n",
       "  0.09756026417016983,\n",
       "  0.09566101431846619,\n",
       "  0.09347055852413177,\n",
       "  0.09155961871147156,\n",
       "  0.08975967019796371,\n",
       "  0.08801772445440292,\n",
       "  0.0859537273645401,\n",
       "  0.08438651263713837,\n",
       "  0.08268126100301743],\n",
       " 'accuracy': [0.6582000255584717,\n",
       "  0.8649799823760986,\n",
       "  0.8903800249099731,\n",
       "  0.9012600183486938,\n",
       "  0.909500002861023,\n",
       "  0.9146599769592285,\n",
       "  0.9197199940681458,\n",
       "  0.9238600134849548,\n",
       "  0.9277399778366089,\n",
       "  0.9306399822235107,\n",
       "  0.9336400032043457,\n",
       "  0.9368000030517578,\n",
       "  0.9384999871253967,\n",
       "  0.9412400126457214,\n",
       "  0.9431999921798706,\n",
       "  0.9447000026702881,\n",
       "  0.9465600252151489,\n",
       "  0.9485200047492981,\n",
       "  0.9499199986457825,\n",
       "  0.951479971408844,\n",
       "  0.9525799751281738,\n",
       "  0.953540027141571,\n",
       "  0.9556000232696533,\n",
       "  0.9564999938011169,\n",
       "  0.9577800035476685,\n",
       "  0.9589200019836426,\n",
       "  0.9600600004196167,\n",
       "  0.9610599875450134,\n",
       "  0.9621599912643433,\n",
       "  0.9631800055503845,\n",
       "  0.9641000032424927,\n",
       "  0.9649999737739563,\n",
       "  0.9658200144767761,\n",
       "  0.9667400121688843,\n",
       "  0.9676200151443481,\n",
       "  0.9682400226593018,\n",
       "  0.9693599939346313,\n",
       "  0.9696800112724304,\n",
       "  0.9704999923706055,\n",
       "  0.9714199900627136,\n",
       "  0.9716600179672241,\n",
       "  0.9725599884986877,\n",
       "  0.9730799794197083,\n",
       "  0.9739400148391724,\n",
       "  0.9746800065040588,\n",
       "  0.9752399921417236,\n",
       "  0.9755799770355225,\n",
       "  0.9758800268173218,\n",
       "  0.9768999814987183,\n",
       "  0.9769999980926514],\n",
       " 'val_loss': [0.620836079120636,\n",
       "  0.3989470601081848,\n",
       "  0.3371826410293579,\n",
       "  0.30554863810539246,\n",
       "  0.2843158543109894,\n",
       "  0.2683121860027313,\n",
       "  0.25522381067276,\n",
       "  0.2440691888332367,\n",
       "  0.23383376002311707,\n",
       "  0.22593632340431213,\n",
       "  0.21722036600112915,\n",
       "  0.21009233593940735,\n",
       "  0.20334181189537048,\n",
       "  0.19846074283123016,\n",
       "  0.19134214520454407,\n",
       "  0.18562373518943787,\n",
       "  0.18092967569828033,\n",
       "  0.17545223236083984,\n",
       "  0.1730731576681137,\n",
       "  0.16852471232414246,\n",
       "  0.1624344140291214,\n",
       "  0.1594679206609726,\n",
       "  0.15600399672985077,\n",
       "  0.15205197036266327,\n",
       "  0.14949926733970642,\n",
       "  0.14677691459655762,\n",
       "  0.14445659518241882,\n",
       "  0.1416797786951065,\n",
       "  0.138738214969635,\n",
       "  0.13651619851589203,\n",
       "  0.13405415415763855,\n",
       "  0.13260404765605927,\n",
       "  0.1307089477777481,\n",
       "  0.12866505980491638,\n",
       "  0.1259586066007614,\n",
       "  0.1252269744873047,\n",
       "  0.12329757213592529,\n",
       "  0.12091934680938721,\n",
       "  0.11866697669029236,\n",
       "  0.11925089359283447,\n",
       "  0.11640523374080658,\n",
       "  0.11496595293283463,\n",
       "  0.1137474998831749,\n",
       "  0.11302413046360016,\n",
       "  0.11117830872535706,\n",
       "  0.10962317883968353,\n",
       "  0.10876787453889847,\n",
       "  0.10764959454536438,\n",
       "  0.1086682379245758,\n",
       "  0.10573580116033554],\n",
       " 'val_accuracy': [0.8640999794006348,\n",
       "  0.8960000276565552,\n",
       "  0.9078999757766724,\n",
       "  0.9158999919891357,\n",
       "  0.920199990272522,\n",
       "  0.9243000149726868,\n",
       "  0.927299976348877,\n",
       "  0.930400013923645,\n",
       "  0.9336000084877014,\n",
       "  0.9358000159263611,\n",
       "  0.9384999871253967,\n",
       "  0.942799985408783,\n",
       "  0.9437999725341797,\n",
       "  0.9456999897956848,\n",
       "  0.947700023651123,\n",
       "  0.9506000280380249,\n",
       "  0.951200008392334,\n",
       "  0.9541000127792358,\n",
       "  0.9534000158309937,\n",
       "  0.9546999931335449,\n",
       "  0.9570000171661377,\n",
       "  0.9574999809265137,\n",
       "  0.9585000276565552,\n",
       "  0.9595000147819519,\n",
       "  0.9595000147819519,\n",
       "  0.9598000049591064,\n",
       "  0.9614999890327454,\n",
       "  0.961899995803833,\n",
       "  0.9621999859809875,\n",
       "  0.9627000093460083,\n",
       "  0.9642000198364258,\n",
       "  0.9641000032424927,\n",
       "  0.9641000032424927,\n",
       "  0.965399980545044,\n",
       "  0.9659000039100647,\n",
       "  0.9660000205039978,\n",
       "  0.9664999842643738,\n",
       "  0.9674000144004822,\n",
       "  0.9675999879837036,\n",
       "  0.9678000211715698,\n",
       "  0.968999981880188,\n",
       "  0.9689000248908997,\n",
       "  0.9688000082969666,\n",
       "  0.9695000052452087,\n",
       "  0.9696000218391418,\n",
       "  0.9696999788284302,\n",
       "  0.9699000120162964,\n",
       "  0.9699000120162964,\n",
       "  0.9708999991416931,\n",
       "  0.97079998254776]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.313822865486145,\n",
       "  0.5273887515068054,\n",
       "  0.40201082825660706,\n",
       "  0.35152527689933777,\n",
       "  0.3213057219982147,\n",
       "  0.29957443475723267,\n",
       "  0.2823467254638672,\n",
       "  0.2676509916782379,\n",
       "  0.25494110584259033,\n",
       "  0.2439156323671341,\n",
       "  0.2337842434644699,\n",
       "  0.22457699477672577,\n",
       "  0.21599292755126953,\n",
       "  0.2081490308046341,\n",
       "  0.2009105086326599,\n",
       "  0.19405585527420044,\n",
       "  0.18748623132705688,\n",
       "  0.18136237561702728,\n",
       "  0.17583927512168884,\n",
       "  0.17025665938854218,\n",
       "  0.16537919640541077,\n",
       "  0.1605926901102066,\n",
       "  0.15580932796001434,\n",
       "  0.15151149034500122,\n",
       "  0.1474505513906479,\n",
       "  0.14343059062957764,\n",
       "  0.13950799405574799,\n",
       "  0.13596297800540924,\n",
       "  0.132553368806839,\n",
       "  0.12904271483421326,\n",
       "  0.12600766122341156,\n",
       "  0.12282603234052658,\n",
       "  0.11985959857702255,\n",
       "  0.11701331287622452,\n",
       "  0.11435963958501816,\n",
       "  0.11158638447523117,\n",
       "  0.10898932814598083,\n",
       "  0.10667763650417328,\n",
       "  0.10423775762319565,\n",
       "  0.10197427868843079,\n",
       "  0.09975337237119675,\n",
       "  0.09756026417016983,\n",
       "  0.09566101431846619,\n",
       "  0.09347055852413177,\n",
       "  0.09155961871147156,\n",
       "  0.08975967019796371,\n",
       "  0.08801772445440292,\n",
       "  0.0859537273645401,\n",
       "  0.08438651263713837,\n",
       "  0.08268126100301743],\n",
       " 'accuracy': [0.6582000255584717,\n",
       "  0.8649799823760986,\n",
       "  0.8903800249099731,\n",
       "  0.9012600183486938,\n",
       "  0.909500002861023,\n",
       "  0.9146599769592285,\n",
       "  0.9197199940681458,\n",
       "  0.9238600134849548,\n",
       "  0.9277399778366089,\n",
       "  0.9306399822235107,\n",
       "  0.9336400032043457,\n",
       "  0.9368000030517578,\n",
       "  0.9384999871253967,\n",
       "  0.9412400126457214,\n",
       "  0.9431999921798706,\n",
       "  0.9447000026702881,\n",
       "  0.9465600252151489,\n",
       "  0.9485200047492981,\n",
       "  0.9499199986457825,\n",
       "  0.951479971408844,\n",
       "  0.9525799751281738,\n",
       "  0.953540027141571,\n",
       "  0.9556000232696533,\n",
       "  0.9564999938011169,\n",
       "  0.9577800035476685,\n",
       "  0.9589200019836426,\n",
       "  0.9600600004196167,\n",
       "  0.9610599875450134,\n",
       "  0.9621599912643433,\n",
       "  0.9631800055503845,\n",
       "  0.9641000032424927,\n",
       "  0.9649999737739563,\n",
       "  0.9658200144767761,\n",
       "  0.9667400121688843,\n",
       "  0.9676200151443481,\n",
       "  0.9682400226593018,\n",
       "  0.9693599939346313,\n",
       "  0.9696800112724304,\n",
       "  0.9704999923706055,\n",
       "  0.9714199900627136,\n",
       "  0.9716600179672241,\n",
       "  0.9725599884986877,\n",
       "  0.9730799794197083,\n",
       "  0.9739400148391724,\n",
       "  0.9746800065040588,\n",
       "  0.9752399921417236,\n",
       "  0.9755799770355225,\n",
       "  0.9758800268173218,\n",
       "  0.9768999814987183,\n",
       "  0.9769999980926514],\n",
       " 'val_loss': [0.620836079120636,\n",
       "  0.3989470601081848,\n",
       "  0.3371826410293579,\n",
       "  0.30554863810539246,\n",
       "  0.2843158543109894,\n",
       "  0.2683121860027313,\n",
       "  0.25522381067276,\n",
       "  0.2440691888332367,\n",
       "  0.23383376002311707,\n",
       "  0.22593632340431213,\n",
       "  0.21722036600112915,\n",
       "  0.21009233593940735,\n",
       "  0.20334181189537048,\n",
       "  0.19846074283123016,\n",
       "  0.19134214520454407,\n",
       "  0.18562373518943787,\n",
       "  0.18092967569828033,\n",
       "  0.17545223236083984,\n",
       "  0.1730731576681137,\n",
       "  0.16852471232414246,\n",
       "  0.1624344140291214,\n",
       "  0.1594679206609726,\n",
       "  0.15600399672985077,\n",
       "  0.15205197036266327,\n",
       "  0.14949926733970642,\n",
       "  0.14677691459655762,\n",
       "  0.14445659518241882,\n",
       "  0.1416797786951065,\n",
       "  0.138738214969635,\n",
       "  0.13651619851589203,\n",
       "  0.13405415415763855,\n",
       "  0.13260404765605927,\n",
       "  0.1307089477777481,\n",
       "  0.12866505980491638,\n",
       "  0.1259586066007614,\n",
       "  0.1252269744873047,\n",
       "  0.12329757213592529,\n",
       "  0.12091934680938721,\n",
       "  0.11866697669029236,\n",
       "  0.11925089359283447,\n",
       "  0.11640523374080658,\n",
       "  0.11496595293283463,\n",
       "  0.1137474998831749,\n",
       "  0.11302413046360016,\n",
       "  0.11117830872535706,\n",
       "  0.10962317883968353,\n",
       "  0.10876787453889847,\n",
       "  0.10764959454536438,\n",
       "  0.1086682379245758,\n",
       "  0.10573580116033554],\n",
       " 'val_accuracy': [0.8640999794006348,\n",
       "  0.8960000276565552,\n",
       "  0.9078999757766724,\n",
       "  0.9158999919891357,\n",
       "  0.920199990272522,\n",
       "  0.9243000149726868,\n",
       "  0.927299976348877,\n",
       "  0.930400013923645,\n",
       "  0.9336000084877014,\n",
       "  0.9358000159263611,\n",
       "  0.9384999871253967,\n",
       "  0.942799985408783,\n",
       "  0.9437999725341797,\n",
       "  0.9456999897956848,\n",
       "  0.947700023651123,\n",
       "  0.9506000280380249,\n",
       "  0.951200008392334,\n",
       "  0.9541000127792358,\n",
       "  0.9534000158309937,\n",
       "  0.9546999931335449,\n",
       "  0.9570000171661377,\n",
       "  0.9574999809265137,\n",
       "  0.9585000276565552,\n",
       "  0.9595000147819519,\n",
       "  0.9595000147819519,\n",
       "  0.9598000049591064,\n",
       "  0.9614999890327454,\n",
       "  0.961899995803833,\n",
       "  0.9621999859809875,\n",
       "  0.9627000093460083,\n",
       "  0.9642000198364258,\n",
       "  0.9641000032424927,\n",
       "  0.9641000032424927,\n",
       "  0.965399980545044,\n",
       "  0.9659000039100647,\n",
       "  0.9660000205039978,\n",
       "  0.9664999842643738,\n",
       "  0.9674000144004822,\n",
       "  0.9675999879837036,\n",
       "  0.9678000211715698,\n",
       "  0.968999981880188,\n",
       "  0.9689000248908997,\n",
       "  0.9688000082969666,\n",
       "  0.9695000052452087,\n",
       "  0.9696000218391418,\n",
       "  0.9696999788284302,\n",
       "  0.9699000120162964,\n",
       "  0.9699000120162964,\n",
       "  0.9708999991416931,\n",
       "  0.97079998254776]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.313823</td>\n",
       "      <td>0.65820</td>\n",
       "      <td>0.620836</td>\n",
       "      <td>0.8641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.527389</td>\n",
       "      <td>0.86498</td>\n",
       "      <td>0.398947</td>\n",
       "      <td>0.8960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.402011</td>\n",
       "      <td>0.89038</td>\n",
       "      <td>0.337183</td>\n",
       "      <td>0.9079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.351525</td>\n",
       "      <td>0.90126</td>\n",
       "      <td>0.305549</td>\n",
       "      <td>0.9159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.321306</td>\n",
       "      <td>0.90950</td>\n",
       "      <td>0.284316</td>\n",
       "      <td>0.9202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.299574</td>\n",
       "      <td>0.91466</td>\n",
       "      <td>0.268312</td>\n",
       "      <td>0.9243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.282347</td>\n",
       "      <td>0.91972</td>\n",
       "      <td>0.255224</td>\n",
       "      <td>0.9273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.267651</td>\n",
       "      <td>0.92386</td>\n",
       "      <td>0.244069</td>\n",
       "      <td>0.9304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.254941</td>\n",
       "      <td>0.92774</td>\n",
       "      <td>0.233834</td>\n",
       "      <td>0.9336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.243916</td>\n",
       "      <td>0.93064</td>\n",
       "      <td>0.225936</td>\n",
       "      <td>0.9358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.233784</td>\n",
       "      <td>0.93364</td>\n",
       "      <td>0.217220</td>\n",
       "      <td>0.9385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.224577</td>\n",
       "      <td>0.93680</td>\n",
       "      <td>0.210092</td>\n",
       "      <td>0.9428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.215993</td>\n",
       "      <td>0.93850</td>\n",
       "      <td>0.203342</td>\n",
       "      <td>0.9438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.208149</td>\n",
       "      <td>0.94124</td>\n",
       "      <td>0.198461</td>\n",
       "      <td>0.9457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.200911</td>\n",
       "      <td>0.94320</td>\n",
       "      <td>0.191342</td>\n",
       "      <td>0.9477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.194056</td>\n",
       "      <td>0.94470</td>\n",
       "      <td>0.185624</td>\n",
       "      <td>0.9506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.187486</td>\n",
       "      <td>0.94656</td>\n",
       "      <td>0.180930</td>\n",
       "      <td>0.9512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.181362</td>\n",
       "      <td>0.94852</td>\n",
       "      <td>0.175452</td>\n",
       "      <td>0.9541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.175839</td>\n",
       "      <td>0.94992</td>\n",
       "      <td>0.173073</td>\n",
       "      <td>0.9534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.170257</td>\n",
       "      <td>0.95148</td>\n",
       "      <td>0.168525</td>\n",
       "      <td>0.9547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.165379</td>\n",
       "      <td>0.95258</td>\n",
       "      <td>0.162434</td>\n",
       "      <td>0.9570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.160593</td>\n",
       "      <td>0.95354</td>\n",
       "      <td>0.159468</td>\n",
       "      <td>0.9575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.155809</td>\n",
       "      <td>0.95560</td>\n",
       "      <td>0.156004</td>\n",
       "      <td>0.9585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.151511</td>\n",
       "      <td>0.95650</td>\n",
       "      <td>0.152052</td>\n",
       "      <td>0.9595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.147451</td>\n",
       "      <td>0.95778</td>\n",
       "      <td>0.149499</td>\n",
       "      <td>0.9595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.143431</td>\n",
       "      <td>0.95892</td>\n",
       "      <td>0.146777</td>\n",
       "      <td>0.9598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.139508</td>\n",
       "      <td>0.96006</td>\n",
       "      <td>0.144457</td>\n",
       "      <td>0.9615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.135963</td>\n",
       "      <td>0.96106</td>\n",
       "      <td>0.141680</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.132553</td>\n",
       "      <td>0.96216</td>\n",
       "      <td>0.138738</td>\n",
       "      <td>0.9622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.129043</td>\n",
       "      <td>0.96318</td>\n",
       "      <td>0.136516</td>\n",
       "      <td>0.9627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.126008</td>\n",
       "      <td>0.96410</td>\n",
       "      <td>0.134054</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.122826</td>\n",
       "      <td>0.96500</td>\n",
       "      <td>0.132604</td>\n",
       "      <td>0.9641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.119860</td>\n",
       "      <td>0.96582</td>\n",
       "      <td>0.130709</td>\n",
       "      <td>0.9641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.117013</td>\n",
       "      <td>0.96674</td>\n",
       "      <td>0.128665</td>\n",
       "      <td>0.9654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.114360</td>\n",
       "      <td>0.96762</td>\n",
       "      <td>0.125959</td>\n",
       "      <td>0.9659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.111586</td>\n",
       "      <td>0.96824</td>\n",
       "      <td>0.125227</td>\n",
       "      <td>0.9660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.108989</td>\n",
       "      <td>0.96936</td>\n",
       "      <td>0.123298</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.106678</td>\n",
       "      <td>0.96968</td>\n",
       "      <td>0.120919</td>\n",
       "      <td>0.9674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.104238</td>\n",
       "      <td>0.97050</td>\n",
       "      <td>0.118667</td>\n",
       "      <td>0.9676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.101974</td>\n",
       "      <td>0.97142</td>\n",
       "      <td>0.119251</td>\n",
       "      <td>0.9678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.099753</td>\n",
       "      <td>0.97166</td>\n",
       "      <td>0.116405</td>\n",
       "      <td>0.9690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.097560</td>\n",
       "      <td>0.97256</td>\n",
       "      <td>0.114966</td>\n",
       "      <td>0.9689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.095661</td>\n",
       "      <td>0.97308</td>\n",
       "      <td>0.113747</td>\n",
       "      <td>0.9688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.093471</td>\n",
       "      <td>0.97394</td>\n",
       "      <td>0.113024</td>\n",
       "      <td>0.9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.091560</td>\n",
       "      <td>0.97468</td>\n",
       "      <td>0.111178</td>\n",
       "      <td>0.9696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.089760</td>\n",
       "      <td>0.97524</td>\n",
       "      <td>0.109623</td>\n",
       "      <td>0.9697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.088018</td>\n",
       "      <td>0.97558</td>\n",
       "      <td>0.108768</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.085954</td>\n",
       "      <td>0.97588</td>\n",
       "      <td>0.107650</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.084387</td>\n",
       "      <td>0.97690</td>\n",
       "      <td>0.108668</td>\n",
       "      <td>0.9709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.082681</td>\n",
       "      <td>0.97700</td>\n",
       "      <td>0.105736</td>\n",
       "      <td>0.9708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.313823   0.65820  0.620836        0.8641\n",
       "1   0.527389   0.86498  0.398947        0.8960\n",
       "2   0.402011   0.89038  0.337183        0.9079\n",
       "3   0.351525   0.90126  0.305549        0.9159\n",
       "4   0.321306   0.90950  0.284316        0.9202\n",
       "5   0.299574   0.91466  0.268312        0.9243\n",
       "6   0.282347   0.91972  0.255224        0.9273\n",
       "7   0.267651   0.92386  0.244069        0.9304\n",
       "8   0.254941   0.92774  0.233834        0.9336\n",
       "9   0.243916   0.93064  0.225936        0.9358\n",
       "10  0.233784   0.93364  0.217220        0.9385\n",
       "11  0.224577   0.93680  0.210092        0.9428\n",
       "12  0.215993   0.93850  0.203342        0.9438\n",
       "13  0.208149   0.94124  0.198461        0.9457\n",
       "14  0.200911   0.94320  0.191342        0.9477\n",
       "15  0.194056   0.94470  0.185624        0.9506\n",
       "16  0.187486   0.94656  0.180930        0.9512\n",
       "17  0.181362   0.94852  0.175452        0.9541\n",
       "18  0.175839   0.94992  0.173073        0.9534\n",
       "19  0.170257   0.95148  0.168525        0.9547\n",
       "20  0.165379   0.95258  0.162434        0.9570\n",
       "21  0.160593   0.95354  0.159468        0.9575\n",
       "22  0.155809   0.95560  0.156004        0.9585\n",
       "23  0.151511   0.95650  0.152052        0.9595\n",
       "24  0.147451   0.95778  0.149499        0.9595\n",
       "25  0.143431   0.95892  0.146777        0.9598\n",
       "26  0.139508   0.96006  0.144457        0.9615\n",
       "27  0.135963   0.96106  0.141680        0.9619\n",
       "28  0.132553   0.96216  0.138738        0.9622\n",
       "29  0.129043   0.96318  0.136516        0.9627\n",
       "30  0.126008   0.96410  0.134054        0.9642\n",
       "31  0.122826   0.96500  0.132604        0.9641\n",
       "32  0.119860   0.96582  0.130709        0.9641\n",
       "33  0.117013   0.96674  0.128665        0.9654\n",
       "34  0.114360   0.96762  0.125959        0.9659\n",
       "35  0.111586   0.96824  0.125227        0.9660\n",
       "36  0.108989   0.96936  0.123298        0.9665\n",
       "37  0.106678   0.96968  0.120919        0.9674\n",
       "38  0.104238   0.97050  0.118667        0.9676\n",
       "39  0.101974   0.97142  0.119251        0.9678\n",
       "40  0.099753   0.97166  0.116405        0.9690\n",
       "41  0.097560   0.97256  0.114966        0.9689\n",
       "42  0.095661   0.97308  0.113747        0.9688\n",
       "43  0.093471   0.97394  0.113024        0.9695\n",
       "44  0.091560   0.97468  0.111178        0.9696\n",
       "45  0.089760   0.97524  0.109623        0.9697\n",
       "46  0.088018   0.97558  0.108768        0.9699\n",
       "47  0.085954   0.97588  0.107650        0.9699\n",
       "48  0.084387   0.97690  0.108668        0.9709\n",
       "49  0.082681   0.97700  0.105736        0.9708"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08582097291946411, 0.9735000133514404]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.003, 0.   , 0.   , 0.   , 0.997, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target, random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9465 - val_loss: 0.5089\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4801 - val_loss: 0.4338\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4228 - val_loss: 0.4148\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4048 - val_loss: 0.3966\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3942 - val_loss: 0.3946\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3879 - val_loss: 0.3865\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3860 - val_loss: 0.3829\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.3855\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3759 - val_loss: 0.3902\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3758 - val_loss: 0.3761\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3777 - val_loss: 0.3803\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3657 - val_loss: 0.3725\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.3710\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.3758\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3593 - val_loss: 0.4050\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5612 - val_loss: 0.3772\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.4038\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3698 - val_loss: 0.3713\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3644\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3555 - val_loss: 0.3646\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3765\n",
      "0.37653276324272156\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.1299431],\n",
       "       [2.60141  ],\n",
       "       [1.0800508],\n",
       "       [0.9726374],\n",
       "       [1.7719171]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open {'model.pkl' , 'rb'} as a:\n",
    "    model = pickle.load(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3521\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3485\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3465\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3451\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3440\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3422A: 0s - los\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3408\n",
      "Epoch 9/30\n",
      "219/363 [=================>............] - ETA: 0s - loss: 0.3336"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MIGUEL~1\\AppData\\Local\\Temp/ipykernel_6572/577377571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                    callbacks = [checkpoint_cb])\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1208\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[0;32m   1210\u001b[0m                 \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1248\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m       \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[0;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    718\u001b[0m     \"\"\"\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m()\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[1;32m--> 690\u001b[1;33m           self.handle, self._dtype)\n\u001b[0m\u001b[0;32m    691\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 470\u001b[1;33m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[0;32m    471\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3196 - val_loss: 0.3466\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3189 - val_loss: 0.3454\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3185 - val_loss: 0.3499\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3597\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3310 - val_loss: 0.3491\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.3487\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3239 - val_loss: 0.3462\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=20,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
